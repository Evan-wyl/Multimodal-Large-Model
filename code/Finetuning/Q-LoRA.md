|       | Links                                                        |
| ----- | ------------------------------------------------------------ |
| Paper | [QLORA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) |
| Code  | https://github.com/artidoro/qlora <br />https://github.com/TimDettmers/bitsandbytes |



## Performance

- Finetuning a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance.
- Best Model reaches 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU.