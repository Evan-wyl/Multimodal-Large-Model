## Vision Language Benchmark

***X  Open represents whether the benchmark is open source,#.X represents the quantity of X, #.T represents the quantity of Text,and X Feat represents on what the benchmark featured***

|                             Name                             |  X Open  | #.X  |                            X Feat                            |
| :----------------------------------------------------------: | :------: | :--: | :----------------------------------------------------------: |
|           [GQA](https://arxiv.org/abs/1902.09506)            |          |      | Real-World Visual Reasoning and Compositional Question Answering |
|     [HM: HatefulMemes](https://arxiv.org/abs/2005.04790)     |          |      |                    Detecting Hate Speech                     |
|             [IconVQA](https://iconqa.github.io/)             | &#x2714; |      | Abstract Diagram Understanding and Visual Language Reasoning |
| [LLaVA-W: LLaVA-Bench (In-the-Wild)](https://arxiv.org/abs/2304.08485) | &#x2714; |      |                  Visual Instruction Tuning                   |
|  [MME-P:  MME Perception](https://arxiv.org/abs/2306.13394)  |          |      |              Comprehensive Evaluation Benchmark              |
|  [MME-C:  MME Cognition](https://arxiv.org/abs/2306.13394)   |          |      |              Comprehensive Evaluation Benchmark              |
|    [MMB :  MMBenchmark](https://arxiv.org/abs/2307.06281)    |          |      |         Systematically-Designed Objective Benchmark          |
| [MMB-CN: MMBench-Chinese](https://arxiv.org/abs/2307.06281)  |          |      |         Systematically-Designed Objective Benchmark          |
| [MM-Vet](https://arxiv.org/abs/2308.02490)[OKVQA](https://allenai.org/project/a-okvqa/home) | &#x2714; |      |                   Integrated Capabilities                    |
|           [POPE](https://github.com/RUCAIBox/POPE)           | &#x2714; |      |                     Object Hallucination                     |
|          [QBench](https://arxiv.org/abs/2309.14181)          | &#x2714; |      |                       Low-level Vision                       |
| [SEED-I:  SEED-Bench (Image)](https://arxiv.org/abs/2307.16125) | &#x2714; |      |                  Multiple-Choice Questions                   |
|     [SQA-I: ScienceQA-IMG](https://scienceqa.github.io/)     | &#x2714; |      |                  Science Question Answering                  |
|          [VQA-v2](https://arxiv.org/abs/1612.00837)          | &#x2714; |      |                  Visual Question Answering                   |
|          [VizWiz](https://arxiv.org/abs/1802.08218)          |          |      |         Answering Visual Questions from Blind People         |
|      [VQA-T: TextVQA](https://arxiv.org/abs/1904.08920)      | &#x2714; |      |                   Complementary to VQA-v2                    |
|           [VSR](https://arxiv.org/abs/2205.00363)            | &#x2714; |      |                   Visual Spatial Reasoning                   |





## Challenging Benchmark

|                             Name                             |  X Open  | #.X  |                            X Feat                            |
| :----------------------------------------------------------: | :------: | :--: | :----------------------------------------------------------: |
|        [BenchLMM](https://github.com/AIFEG/BenchLMM)         | &#x2714; |      |                Cross-style Visual Capability                 |
|          [CMMU](https://cmmmu-benchmark.github.io/)          | &#x2714; |      |               Chinese Massive Multi-discipline               |
|           [GOAT-Bench](https://goatlmm.github.io/)           | &#x2714; |      |                       Safety Insights                        |
| [LLaVA-Bench](https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings) | &#x2714; |      |         Multimodal Instruction-Following benchmark.          |
|          [MMMU](https://mmmu-benchmark.github.io/)           | &#x2714; |      | Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark |
|          [MathVista](https://mathvista.github.io/)           | &#x2714; |      |        Evaluating Math Reasoning in Visual Contexts.         |

